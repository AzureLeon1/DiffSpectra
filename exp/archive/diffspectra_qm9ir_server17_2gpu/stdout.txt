INFO - run_lib.py - 2025-03-17 21:51:55,334 - model size: 125.0MB
WARNING - utils.py - 2025-03-17 21:51:55,335 - No checkpoint found at exp/diffspectra_qm9ir_server17_2gpu/checkpoints-meta/checkpoint.pth. Returned the same state as input
INFO - run_lib.py - 2025-03-17 21:51:55,335 - data:
  atom_types: 5
  bond_types: 4
  centered: true
  collate: collate_spectra_ir
  compress_edge: true
  fc_scale:
  - -1.0
  - 1.0
  include_aromatic: false
  info_name: qm9_second_half
  max_node: 29
  name: QM9
  num_workers: 16
  processed_file: ''
  root: /home/wangliang/datasets/MolGeneration/DiffSpectra/QM9
  spectra_version: ir
  transform: EdgeComSpectra
  use_normalize: true
device: !!python/object/apply:torch.device
- cuda
- 0
eval:
  batch_size: 2500
  begin_ckpt: 40
  ckpts: ''
  enable_sampling: true
  end_ckpt: 40
  num_samples: 10000
  save_graph: false
  save_mols: 'true'
  sub_geometry: false
exp_type: vpsde_edge_diffspectra
model:
  CoM: true
  cond_ch: 1
  cond_time: true
  dist_gbf: true
  dropout: 0.1
  edge_ch: 2
  edge_quan_th: 0.0
  ema_decay: 0.999
  gbf_name: CondGaussianLayer
  include_fc_charge: true
  loss_weights: 1., 0.25, 0.1
  mlp_ratio: 2
  n_extra_heads: 2
  n_heads: 16
  n_layers: 8
  name: diffspectra_cond_DGT_concat
  nf: 256
  noise_align: true
  normalize_factors: 1, 4, 4, 1
  patch_len:
  - 20
  - 50
  - 50
  pred_data: true
  self_cond: true
  self_cond_type: ori
  softmax_inf: true
  spatial_cut_off: 2.0
  stride:
  - 10
  - 25
  - 25
  trans_name: TransMixLayer
only_2D: false
optim:
  beta1: 0.9
  disable_grad_log: true
  eps: 1.0e-08
  grad_clip: 10.0
  lr: 0.0002
  optimizer: AdamW
  warmup: 100000
  weight_decay: 0
pred_edge: true
sampling:
  method: ancestral
  steps: 1000
  vis_col: 4
  vis_row: 4
sde:
  continuous_beta_0: 0.1
  continuous_beta_1: 20.0
  schedule: cosine
seed: 42
training:
  batch_size: 256
  dataloader_drop_last: true
  distributed: true
  eval_batch_size: 256
  eval_samples: 256
  local_rank: 0
  log_freq: 250
  n_iters: 1000000
  num_gpus: 2
  reduce_mean: false
  snapshot_freq: 25000
  snapshot_freq_for_preemption: 5000
  snapshot_sampling: true
  world_size: 2

INFO - run_lib.py - 2025-03-17 21:51:55,471 - loading test mols
INFO - run_lib.py - 2025-03-17 21:52:16,091 - step: 0, training_loss: 4.78345e+01
INFO - run_lib.py - 2025-03-17 21:54:18,881 - step: 250, training_loss: 4.42382e+01
INFO - run_lib.py - 2025-03-17 21:56:20,473 - step: 500, training_loss: 3.52499e+01
INFO - run_lib.py - 2025-03-17 21:58:20,765 - step: 750, training_loss: 1.84491e+01
INFO - run_lib.py - 2025-03-17 22:00:20,462 - step: 1000, training_loss: 1.48935e+01
INFO - run_lib.py - 2025-03-17 22:02:20,568 - step: 1250, training_loss: 1.14751e+01
INFO - run_lib.py - 2025-03-17 22:04:20,792 - step: 1500, training_loss: 1.06176e+01
INFO - run_lib.py - 2025-03-17 22:06:21,952 - step: 1750, training_loss: 1.14747e+01
INFO - run_lib.py - 2025-03-17 22:08:21,005 - step: 2000, training_loss: 1.10646e+01
INFO - run_lib.py - 2025-03-17 22:10:21,746 - step: 2250, training_loss: 1.09169e+01
INFO - run_lib.py - 2025-03-17 22:12:24,310 - step: 2500, training_loss: 9.92221e+00
INFO - run_lib.py - 2025-03-17 22:14:25,320 - step: 2750, training_loss: 1.09672e+01
INFO - run_lib.py - 2025-03-17 22:16:24,842 - step: 3000, training_loss: 1.08201e+01
INFO - run_lib.py - 2025-03-17 22:18:26,339 - step: 3250, training_loss: 9.83654e+00
INFO - run_lib.py - 2025-03-17 22:20:27,261 - step: 3500, training_loss: 9.34182e+00
INFO - run_lib.py - 2025-03-17 22:22:25,386 - step: 3750, training_loss: 9.97181e+00
INFO - run_lib.py - 2025-03-17 22:24:28,144 - step: 4000, training_loss: 1.03813e+01
INFO - run_lib.py - 2025-03-17 22:26:28,165 - step: 4250, training_loss: 1.02429e+01
INFO - run_lib.py - 2025-03-17 22:28:30,900 - step: 4500, training_loss: 9.93001e+00
INFO - run_lib.py - 2025-03-17 22:30:34,370 - step: 4750, training_loss: 1.00229e+01
INFO - run_lib.py - 2025-03-17 22:32:33,988 - step: 5000, training_loss: 9.17294e+00
INFO - run_lib.py - 2025-03-17 22:34:34,485 - step: 5250, training_loss: 1.01040e+01
INFO - run_lib.py - 2025-03-17 22:36:36,498 - step: 5500, training_loss: 1.02815e+01
INFO - run_lib.py - 2025-03-17 22:38:36,201 - step: 5750, training_loss: 9.03593e+00
INFO - run_lib.py - 2025-03-17 22:40:37,380 - step: 6000, training_loss: 9.63623e+00
INFO - run_lib.py - 2025-03-17 22:42:41,070 - step: 6250, training_loss: 9.83945e+00
INFO - run_lib.py - 2025-03-17 22:44:39,672 - step: 6500, training_loss: 9.82758e+00
INFO - run_lib.py - 2025-03-17 22:46:39,432 - step: 6750, training_loss: 8.64795e+00
INFO - run_lib.py - 2025-03-17 22:48:40,972 - step: 7000, training_loss: 9.14630e+00
INFO - run_lib.py - 2025-03-17 22:50:42,698 - step: 7250, training_loss: 8.17229e+00
INFO - run_lib.py - 2025-03-17 22:52:43,630 - step: 7500, training_loss: 8.74076e+00
INFO - run_lib.py - 2025-03-17 22:54:46,945 - step: 7750, training_loss: 9.10435e+00
INFO - run_lib.py - 2025-03-17 22:56:46,986 - step: 8000, training_loss: 8.51397e+00
INFO - run_lib.py - 2025-03-17 22:58:44,583 - step: 8250, training_loss: 9.30825e+00
INFO - run_lib.py - 2025-03-17 23:00:43,437 - step: 8500, training_loss: 9.76902e+00
INFO - run_lib.py - 2025-03-17 23:02:46,412 - step: 8750, training_loss: 9.99298e+00
INFO - run_lib.py - 2025-03-17 23:04:45,985 - step: 9000, training_loss: 9.63314e+00
INFO - run_lib.py - 2025-03-17 23:06:47,020 - step: 9250, training_loss: 9.23195e+00
